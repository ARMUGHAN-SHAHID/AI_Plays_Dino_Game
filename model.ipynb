{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\firzok.nadeem\\AppData\\Local\\Continuum\\anaconda3\\envs\\AI_Bot\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model():\n",
    "    def __init__(self,params):\n",
    "        self.input_shape=params['input_shape']\n",
    "        self.num_outputs=params['num_outputs']\n",
    "        self.fully_connected_hierarchy=params['fc_hierarchy']\n",
    "        self.conv_hierarchy=params['conv_hierarchy']\n",
    "        self.activation_fn=params.get('activation_fn',tf.nn.relu)\n",
    "        self.loss_fn=params.get('loss_fn',tf.losses.softmax_cross_entropy)\n",
    "        self.learning_rate=params['learning_rate']\n",
    "        self.optimizer_fn=params['optimizer_fn']\n",
    "#         logdir=params['logdir']\n",
    "        self.form_model()\n",
    "    def form_placeholders(self,input_shape,dt=tf.float32):\n",
    "        X=tf.placeholder(dt,shape=input_shape)\n",
    "        return X\n",
    "    def form_convolutional_heirarchy(self,inputs,initializer):\n",
    "        layer_input=inputs\n",
    "        for layer in self.conv_hierachy:\n",
    "            if layer['layer_type']=='conv_layer':\n",
    "                layer_output=tf.layers.conv2d(\n",
    "                        inputs=layer_input,\n",
    "                        filters=layer['num_filters'],\n",
    "                        kernel_size=layer['kernel_size'],\n",
    "                        strides=layer['kernel_strides'],\n",
    "                        padding=layer['padding'],\n",
    "                        kernel_initializer=initializer,\n",
    "                        activation=self.activation_fn\n",
    "                )\n",
    "                layer_input=layer_output\n",
    "            elif layer['layer_type']=='pool_layer':\n",
    "                layer_output=tf.layers.max_pooling2d(\n",
    "                        inputs=layer_input,\n",
    "                        pool_size=layer['pool_size'],\n",
    "                        strides=layer['pool_strides'])\n",
    "                layer_input=layer_output\n",
    "        return layer_output\n",
    "    \n",
    "    def form_fc_layers(self,inputs,initializer):\n",
    "        layer_inputs=inputs\n",
    "        for num_neurons in self.fc_hierarchy:\n",
    "            layer_outputs=tf.layers.dense(layer_inputs,num_neurons,activation=self.activation_fn,kernel_initializer=initializer)\n",
    "            layer_inputs=layer_outputs\n",
    "        return layer_outputs\n",
    "    def form_loss(self,logits,targets):\n",
    "        entropies=self.loss_fn(onehot_labels=targets,logits=logits)\n",
    "        return entropies\n",
    "    \n",
    "    def form_model(self):\n",
    "        initializer_fn=tf.contrib.layers.variance_scaling_initializer()\n",
    "        self.X=form_placeholders(input_shape)\n",
    "        self.Y=form_placeholders((1,self.num_outputs),tf.int32)\n",
    "        conv_output=form_convolutional_heirarchy(self.X,initializer_fn)\n",
    "        \n",
    "        flat_conv_output=tf.contrib.layers.flatten(conv_output)\n",
    "        \n",
    "        last_fc_output=form_fc_layers(flat_conv_output,initializer_fn)\n",
    "        \n",
    "        logits=tf.layers.dense(last_fc_output,self.num_outputs,kernel_initializer=initializer_fn)\n",
    "        self.logits=logits\n",
    "#         self.outputs=tf.nn.softmax(self.logits)\n",
    "#         self.action=tf.multinomial(tf.log(self.outputs),num_samples=1)\n",
    "        \n",
    "#         targets=self.action[:][0]\n",
    "        \n",
    "        self.loss=form_loss(logits, Y, loss_fn)\n",
    "        optimizer=self.optimizer(learning_rate=0.001)\n",
    "        self.train_op=optimizer.minimize(loss = self.loss) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'input_shape':[None, 190, 35, 1],\n",
    "    'num_outputs':3,\n",
    "    'fc_hierarchy':[100, 50],\n",
    "    'conv_hierarchy':[\n",
    "        {'layer_type':'conv_layer','kernel_size':3,'kernel_strides':1,'num_filters':5,'padding':'valid'},\n",
    "#         {'layer_type':'pool_layer','pool_size':3,'pool_strides':1},\n",
    "        {'layer_type':'conv_layer','kernel_size':3,'kernel_strides':1,'num_filters':10,'padding':'valid'},\n",
    "        \n",
    "#         {'layer_type':'conv_layer','kernel_size':3,'kernel_strides':1,'num_filters':10,'padding':'valid'},\n",
    "#         {'layer_type':'pool_layer','pool_size':3,'pool_strides':1}\n",
    "       \n",
    "    ],\n",
    "    'activation_fn':tf.nn.relu,\n",
    "    'loss_fn':tf.losses.softmax_cross_entropy,\n",
    "    'learning_rate':0.01,\n",
    "    'optimizer_fn':tf.train.AdamOptimizer,\n",
    "    'logdir':'/tf_logs_rnn/run/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-3ebe8de82f60>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-23-3ebe8de82f60>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    print (training_data[][0])\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "n_iter = 20\n",
    "batch_size = 120\n",
    "fileName = 'training_data.npy'\n",
    "training_data = list(np.load(fileName))\n",
    "\n",
    "\n",
    "totalFrames = len(training_data)\n",
    "\n",
    "print (training_data[][0])\n",
    "\n",
    "# with tf.Session() as sess:\n",
    "#     model=CNN_Model(params)\n",
    "#     for iteration in range(n_iter):\n",
    "#         print ('current iteration '+str(iteration))\n",
    "#         feed_dic = {train}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
