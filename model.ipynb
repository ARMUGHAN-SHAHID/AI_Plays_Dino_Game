{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Armughan.Shahid\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "C:\\Users\\Armughan.Shahid\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "from data import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params():#used to store parameter values\n",
    "    def __init__(self,params):\n",
    "        #STORING PARAMETER VALUES \n",
    "        self.input_shape=params['input_shape']\n",
    "        self.num_outputs=params['num_outputs']\n",
    "        self.layer_hierarchy=params['layer_hierarchy']\n",
    "        self.activation_fn=params.get('activation_fn',tf.nn.relu)\n",
    "        self.loss_fn=params.get('loss_fn',tf.losses.softmax_cross_entropy)\n",
    "        self.learning_rate=params['learning_rate']\n",
    "        self.optimizer_fn=params['optimizer_fn']\n",
    "        self.initializer_fn=params['initializer_fn']\n",
    "        self.name_scope=params['name_scope']\n",
    "        logdir=params['logdir']\n",
    "#         self.step_no=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Model():\n",
    "    def __init__(self,param_dict={},restore_params=False,pickle_file_path=\"\"):\n",
    "        #STORING PARAMETER VALUES\n",
    "        if not restore_params:\n",
    "            self.params=Params(param_dict)\n",
    "        else:\n",
    "            self.restore_params_fn(pickle_file_path)\n",
    "\n",
    "    def form_placeholder(self,shape,dt=tf.float32):\n",
    "        X=tf.placeholder(dt,shape=shape)\n",
    "        return X\n",
    "    def form_variable(self,shape,dt=tf.float32,name=\"\",trainable=True,initializer=tf.zeros_initializer):\n",
    "        if name==\"\":\n",
    "            return tf.Variable(initial_value=initializer,trainable=trainable,dtype=dt)\n",
    "        else:\n",
    "#             initializer=tf.constant_initializer(initail_val)\n",
    "            return tf.get_variable(name=name,shape=shape, dtype=dt,initializer=initializer(),trainable=trainable)\n",
    "    \n",
    "    def form_convolutional_layer(self,inputs,layer_params):\n",
    "        return tf.layers.conv2d(\n",
    "                    inputs=inputs,\n",
    "                    filters=layer_params['num_filters'],\n",
    "                    kernel_size=layer_params['kernel_size'],\n",
    "                    strides=layer_params['kernel_strides'],\n",
    "                    padding=layer_params['padding'],\n",
    "                    kernel_initializer=self.params.initializer_fn(),\n",
    "                    activation=None)\n",
    "    def form_max_pooling_layer(self,inputs,layer_params):\n",
    "        tf.layers.max_pooling2d(\n",
    "                    inputs=inputs,\n",
    "                    pool_size=layer_params['pool_size'],\n",
    "                    strides=layer_params['pool_strides'])\n",
    "    def form_activation_layer(self,inputs):\n",
    "        return self.params.activation_fn(inputs)\n",
    "    \n",
    "    def form_fc_layer(self,inputs,layer_params):\n",
    "        return tf.layers.dense(inputs,layer_params['num_hidden_units'],activation=None,kernel_initializer=self.params.initializer_fn())\n",
    "    \n",
    "    def form_batch_normalization_layer(self,inputs):\n",
    "        return tf.layers.batch_normalization(inputs=inputs,axis=-1,training=self.training_mode)\n",
    "        \n",
    "    def form_loss(self,logits,targets):\n",
    "        entropies=self.params.loss_fn(onehot_labels=targets,logits=logits,reduction=tf.losses.Reduction.NONE)\n",
    "        return entropies\n",
    "    \n",
    "    def build_model(self):\n",
    "        with tf.variable_scope(self.params.name_scope):\n",
    "            self.X=self.form_placeholder(self.params.input_shape)\n",
    "            self.Y=self.form_placeholder((None,self.params.num_outputs),tf.float32)\n",
    "            self.lr_placeholder=self.form_placeholder([]) #since we can change learning arate during training\n",
    "            self.training_mode=self.form_placeholder([],tf.bool)\n",
    "            self.step_no=self.form_variable(shape=[],name=\"step_no\",trainable=False)#stores number of steps for which training has occured\n",
    "            self.epoch_no=self.form_variable(shape=[],name=\"epoch_no\",trainable=False) #stores number of epochs for which training is performed\n",
    "            \n",
    "            inputs=self.X\n",
    "            for layer_params in self.params.layer_hierarchy:\n",
    "                if layer_params['layer_type']=='conv_layer':\n",
    "                    inputs=self.form_convolutional_layer(inputs,layer_params)\n",
    "                elif layer_params['layer_type']=='fc_layer':\n",
    "                    inputs=self.form_fc_layer(inputs,layer_params)\n",
    "                elif layer_params['layer_type']=='activation_layer':\n",
    "                    inputs=self.form_activation_layer(inputs)\n",
    "                elif layer_params['layer_type']=='pooling_layer':\n",
    "                    inputs=self.form_max_pooling_layer(inputs,layer_params)\n",
    "                elif layer_params['layer_type']=='flattening_layer':\n",
    "                    inputs=tf.contrib.layers.flatten(inputs)\n",
    "                elif layer_params['layer_type']=='batch_normalization_layer':\n",
    "                    inputs=self.form_batch_normalization_layer(inputs)\n",
    "\n",
    "    #         making logits layer (final output layer)\n",
    "            self.logits=tf.layers.dense(inputs,self.params.num_outputs,activation=None,kernel_initializer=self.params.initializer_fn())\n",
    "            self.loss=tf.reduce_mean(self.form_loss(self.logits,self.Y))            \n",
    "           \n",
    "            self.predictions=tf.argmax(tf.nn.softmax(self.logits),1)\n",
    "            equality = tf.equal(self.predictions,tf.argmax(self.Y,1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(equality, tf.float32))\n",
    "            \n",
    "            optimizer=self.params.optimizer_fn(learning_rate=self.lr_placeholder)\n",
    "            self.train_op=optimizer.minimize(loss = self.loss,global_step=self.step_no)\n",
    "            self.initializer=tf.global_variables_initializer()\n",
    "            \n",
    "            #summary ops\n",
    "            loss_summary=tf.summary.scalar(\"loss\",self.loss)\n",
    "            acc_summary=tf.summary.scalar(\"accuracy\",self.accuracy)\n",
    "#             self.summaries=tf.summary.merge_all(scope=self.params.name_scope)\n",
    "            self.summaries=tf.summary.merge([loss_summary,acc_summary])\n",
    "        model_variables=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.params.name_scope)#saving only the varuiables belonging to this scope\n",
    "        self.saver=tf.train.Saver(var_list=model_variables)\n",
    "        self.increment_epoch_op=tf.assign(self.epoch_no, self.epoch_no+1)#op to update number of epoch by + 1\n",
    "        \n",
    "    def create_log_directory_if_doesnt_exist(self,savedir):\n",
    "        savedir=os.path.join(os.getcwd(),savedir)\n",
    "        savedir=os.path.join(savedir,self.params.name_scope)\n",
    "        savedir=os.path.join(savedir,\"logs\")\n",
    "        if not os.path.isdir(savedir):#creating directory if not exists\n",
    "            try:  \n",
    "                os.makedirs(savedir)\n",
    "                return savedir,True\n",
    "            except OSError:\n",
    "                print ('failed to make the specified_directory.Returning...')\n",
    "                return \"\",False\n",
    "        return savedir,True\n",
    "            \n",
    "        \n",
    "    def save_model(self,sess,savedir=\"/\",step=0):\n",
    "        savedir=os.path.join(os.getcwd(),savedir)\n",
    "        savedir=os.path.join(savedir,self.params.name_scope)\n",
    "        if not hasattr(self,'saved_before'):#calling save model for the first time\n",
    "            if not os.path.isdir(savedir):#creating directory if not exists\n",
    "                try:  \n",
    "                    os.makedirs(savedir)\n",
    "                except OSError:\n",
    "                    print ('failed to make the specified_directory.Returning...')\n",
    "                    return\n",
    "            file_pi = open(os.path.join(savedir,\"model_object.pkl\"), 'wb+') #saving param object\n",
    "            pickle.dump(self.params, file_pi)\n",
    "            #saving tensorflow graph and weight values\n",
    "#             path=os.path.join(savedir,(self.params.name_scope+\".ckpt\"))\n",
    "#             print (\"saving path:{}\".format(str(savedir)))\n",
    "            self.saver.save(sess,os.path.join(savedir,\"model_weights.ckpt\"), global_step=step) #saving model weights\n",
    "            self.saved_before=True\n",
    "        else:    #saving model weights\n",
    "            self.saver.save(sess,os.path.join(savedir,\"model_weights.ckpt\"), global_step=step,write_meta_graph=False)#writes meta graph for the first time save_model is called\n",
    "    def restore_params_fn(self,pickle_file_path):\n",
    "        if os.path.exists(pickle_file_path):\n",
    "            filehandler = open(pickle_file_path, 'rb')\n",
    "            self.params=pickle.load(filehandler)\n",
    "        else:\n",
    "            print(\"no such file exists\")\n",
    "        \n",
    "    def restore_model(self,sess,restore_dir):\n",
    "        restore_dir=os.path.join(os.getcwd(),restore_dir)\n",
    "#         restore_dir=os.path.join(restore_dir,\"\\\\\")\n",
    "#         path=restore_dir\n",
    "        restore_dir=os.path.join(restore_dir,self.params.name_scope)\n",
    "        print (\"restoring path:{}\".format(str(restore_dir)))\n",
    "#         print (path)\n",
    "        self.saver.restore(sess, tf.train.latest_checkpoint(restore_dir))#loading latest model\n",
    "         \n",
    "    def train(self,sess,n_epochs,get_next_batch_fn,get_validation_set_fn,save_every_n_iter,log_train_every_n_iter,log_validation_every_n_iter,save_dir,initialize=False,set_logging=True):\n",
    "        if initialize:\n",
    "            sess.run([self.initializer])\n",
    "        if set_logging:\n",
    "            log_dir,set_logging=self.create_log_directory_if_doesnt_exist(save_dir)\n",
    "        if set_logging: #creating file handlers if dir cretaed or found in above statement\n",
    "            \n",
    "            train_writer = tf.summary.FileWriter(os.path.join(log_dir,'train'), sess.graph)\n",
    "            validation_writer = tf.summary.FileWriter(os.path.join(log_dir ,'validation'))\n",
    "        [step_no]=sess.run([self.step_no]) \n",
    "        [epoch]=sess.run([self.epoch_no])\n",
    "        ending_epoch=n_epochs+epoch\n",
    "        while epoch < ending_epoch:\n",
    "            print(\"----Epoch=\"+str(epoch)+\"\\n\")\n",
    "            for x,y in get_next_batch_fn():\n",
    "                feed_dict={self.X:x,self.Y:y,self.lr_placeholder:self.params.learning_rate,self.training_mode:True}\n",
    "                if step_no%log_train_every_n_iter==0 and set_logging:\n",
    "                    summaries,loss,acc,new_step_no,_=sess.run([self.summaries,self.loss,self.accuracy,self.step_no,self.train_op],feed_dict=feed_dict)\n",
    "                    train_writer.add_summary(summaries,step_no)\n",
    "                else:\n",
    "                    loss,acc,new_step_no,_=sess.run([self.loss,self.accuracy,self.step_no,self.train_op],feed_dict=feed_dict)\n",
    "                print (\"Step={} and loss occured= {} and acc= {} \\n\".format(str(step_no),str(loss),str(acc)))\n",
    "                feed_dict=None #freeing memory\n",
    "                x=y=None\n",
    "                if step_no%log_validation_every_n_iter==0 and set_logging:\n",
    "                    x,y=get_validation_set_fn()\n",
    "                    feed_dict={self.X:x,self.Y:y,self.training_mode:False}\n",
    "                    [summaries]=sess.run([self.summaries],feed_dict=feed_dict)\n",
    "                    validation_writer.add_summary(summaries, step_no)\n",
    "\n",
    "                if (step_no)%save_every_n_iter==0:\n",
    "                    print(\"saving model\\n\")\n",
    "                    self.save_model(sess,save_dir,self.step_no)\n",
    "                step_no=new_step_no\n",
    "#                 print (\"\"\"loss= \"+str(loss)+\"\\n\")\n",
    "            _,epoch=sess.run([self.increment_epoch_op,self.epoch_no])\n",
    "    \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "    'input_shape':[None, 35, 190, 1],\n",
    "    'num_outputs':3,\n",
    "    \n",
    "    'layer_hierarchy':[\n",
    "        {'layer_type':'conv_layer','kernel_size':8,'kernel_strides':1,'num_filters':16,'padding':'valid'},\n",
    "        {'layer_type':'batch_normalization_layer'},\n",
    "        {'layer_type':'activation_layer'},\n",
    "        {'layer_type':'conv_layer','kernel_size':4,'kernel_strides':1,'num_filters':32,'padding':'valid'},\n",
    "        {'layer_type':'batch_normalization_layer'},\n",
    "        {'layer_type':'activation_layer'},\n",
    "        {'layer_type':'flattening_layer'},\n",
    "        {'layer_type':'fc_layer','num_hidden_units':256},\n",
    "        {'layer_type':'batch_normalization_layer'},\n",
    "        {'layer_type':'activation_layer'},\n",
    "        {'layer_type':'fc_layer','num_hidden_units':100},\n",
    "        {'layer_type':'batch_normalization_layer'},\n",
    "        {'layer_type':'activation_layer'}\n",
    "        \n",
    "    ],\n",
    "    'initializer_fn':tf.contrib.layers.variance_scaling_initializer,\n",
    "    'activation_fn':tf.nn.relu,\n",
    "    'loss_fn':tf.losses.softmax_cross_entropy,\n",
    "    'learning_rate':0.001,\n",
    "    'optimizer_fn':tf.train.AdamOptimizer,\n",
    "    'logdir':'/tf_logs_rnn/run/',\n",
    "    'name_scope':'neural_network_bn'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing model \n",
    "# tf.reset_default_graph()\n",
    "# model=CNN_Model(params)\n",
    "# model.build_model()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(model.initializer)\n",
    "#     model.save_model(sess,\"1st_try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #testing restoring a new model\n",
    "# tf.reset_default_graph()\n",
    "# model=CNN_Model(restore_params=True,pickle_file_path=\"1st_try/neural_network_v1.pkl\")\n",
    "# model.build_model()\n",
    "# with tf.Session() as sess:\n",
    "#     model.restore_model(sess,\"1st_try\")\n",
    "# #     sess.run(model.initializer)\n",
    "# #     model.save_model(sess,\"1st_try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'X_train shape': (7273, 35, 190, 1), 'Y_train shape': (7273, 3), 'X_validation shape': (200, 35, 190, 1), 'Y_validation shape': (200, 3), 'X_test shape': (2491, 35, 190, 1), 'Y_test shape': (2491, 3)}\n"
     ]
    }
   ],
   "source": [
    "batch_size=120\n",
    "data=Data(data_path='training_data.npy',batch_size=batch_size,load_directly=True,X_data_path=\"data_X.npy\",Y_data_path=\"data_Y.npy\")\n",
    "print (data.get_shapes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Epoch=0.0\n",
      "\n",
      "Step=0.0 and loss occured= 1.0316405 and acc= 0.51666665 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=0.0 and loss occured= 1.5807884 and acc= 0.51666665 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=1.0 and loss occured= 1.1452049 and acc= 0.575 \n",
      "\n",
      "Step=2.0 and loss occured= 1.0966299 and acc= 0.5416667 \n",
      "\n",
      "Step=3.0 and loss occured= 0.96172017 and acc= 0.56666666 \n",
      "\n",
      "Step=4.0 and loss occured= 0.99233896 and acc= 0.60833335 \n",
      "\n",
      "Step=5.0 and loss occured= 0.8116922 and acc= 0.6666667 \n",
      "\n",
      "Step=6.0 and loss occured= 0.77726454 and acc= 0.69166666 \n",
      "\n",
      "Step=7.0 and loss occured= 0.74314225 and acc= 0.73333335 \n",
      "\n",
      "Step=8.0 and loss occured= 0.7606924 and acc= 0.7083333 \n",
      "\n",
      "Step=9.0 and loss occured= 0.73241806 and acc= 0.7083333 \n",
      "\n",
      "Step=10.0 and loss occured= 0.6109405 and acc= 0.825 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=11.0 and loss occured= 0.7381944 and acc= 0.75 \n",
      "\n",
      "Step=12.0 and loss occured= 0.82872075 and acc= 0.7 \n",
      "\n",
      "Step=13.0 and loss occured= 0.7124406 and acc= 0.775 \n",
      "\n",
      "Step=14.0 and loss occured= 0.54564875 and acc= 0.8666667 \n",
      "\n",
      "Step=15.0 and loss occured= 0.65546924 and acc= 0.78333336 \n",
      "\n",
      "Step=16.0 and loss occured= 0.8359016 and acc= 0.7416667 \n",
      "\n",
      "Step=17.0 and loss occured= 0.73669773 and acc= 0.76666665 \n",
      "\n",
      "Step=18.0 and loss occured= 0.60314906 and acc= 0.8333333 \n",
      "\n",
      "Step=19.0 and loss occured= 0.66927904 and acc= 0.7916667 \n",
      "\n",
      "Step=20.0 and loss occured= 0.53164786 and acc= 0.875 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=21.0 and loss occured= 0.8628003 and acc= 0.7083333 \n",
      "\n",
      "Step=22.0 and loss occured= 0.6874393 and acc= 0.78333336 \n",
      "\n",
      "Step=23.0 and loss occured= 0.62460417 and acc= 0.825 \n",
      "\n",
      "Step=24.0 and loss occured= 0.8049533 and acc= 0.7916667 \n",
      "\n",
      "Step=25.0 and loss occured= 0.5929733 and acc= 0.825 \n",
      "\n",
      "Step=26.0 and loss occured= 0.886494 and acc= 0.73333335 \n",
      "\n",
      "Step=27.0 and loss occured= 0.6955745 and acc= 0.775 \n",
      "\n",
      "Step=28.0 and loss occured= 0.8613946 and acc= 0.73333335 \n",
      "\n",
      "Step=29.0 and loss occured= 0.52717185 and acc= 0.8833333 \n",
      "\n",
      "Step=30.0 and loss occured= 0.5525218 and acc= 0.8333333 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=31.0 and loss occured= 0.45798844 and acc= 0.85833335 \n",
      "\n",
      "Step=32.0 and loss occured= 0.7007777 and acc= 0.78333336 \n",
      "\n",
      "Step=33.0 and loss occured= 0.65154725 and acc= 0.81666666 \n",
      "\n",
      "Step=34.0 and loss occured= 0.58273 and acc= 0.85 \n",
      "\n",
      "Step=35.0 and loss occured= 0.83004105 and acc= 0.7416667 \n",
      "\n",
      "Step=36.0 and loss occured= 0.58530766 and acc= 0.825 \n",
      "\n",
      "Step=37.0 and loss occured= 0.7259179 and acc= 0.76666665 \n",
      "\n",
      "Step=38.0 and loss occured= 0.6439325 and acc= 0.7916667 \n",
      "\n",
      "Step=39.0 and loss occured= 0.8360775 and acc= 0.75 \n",
      "\n",
      "Step=40.0 and loss occured= 0.6810454 and acc= 0.78333336 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=41.0 and loss occured= 0.70649123 and acc= 0.775 \n",
      "\n",
      "Step=42.0 and loss occured= 0.7612497 and acc= 0.7583333 \n",
      "\n",
      "Step=43.0 and loss occured= 0.57108295 and acc= 0.825 \n",
      "\n",
      "Step=44.0 and loss occured= 0.6070067 and acc= 0.81666666 \n",
      "\n",
      "Step=45.0 and loss occured= 0.7801241 and acc= 0.76666665 \n",
      "\n",
      "Step=46.0 and loss occured= 0.7137731 and acc= 0.8 \n",
      "\n",
      "Step=47.0 and loss occured= 0.5571664 and acc= 0.8333333 \n",
      "\n",
      "Step=48.0 and loss occured= 0.6605204 and acc= 0.8 \n",
      "\n",
      "Step=49.0 and loss occured= 0.50788254 and acc= 0.875 \n",
      "\n",
      "Step=50.0 and loss occured= 0.67854774 and acc= 0.7916667 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=51.0 and loss occured= 0.56227547 and acc= 0.84166664 \n",
      "\n",
      "Step=52.0 and loss occured= 0.49797755 and acc= 0.85833335 \n",
      "\n",
      "Step=53.0 and loss occured= 0.5800057 and acc= 0.825 \n",
      "\n",
      "Step=54.0 and loss occured= 0.6586822 and acc= 0.78333336 \n",
      "\n",
      "Step=55.0 and loss occured= 0.599116 and acc= 0.8 \n",
      "\n",
      "Step=56.0 and loss occured= 0.49707174 and acc= 0.8666667 \n",
      "\n",
      "Step=57.0 and loss occured= 0.4789644 and acc= 0.8666667 \n",
      "\n",
      "Step=58.0 and loss occured= 0.7167473 and acc= 0.76666665 \n",
      "\n",
      "----Epoch=0.0\n",
      "\n",
      "Step=59.0 and loss occured= 0.4859282 and acc= 0.8333333 \n",
      "\n",
      "Step=60.0 and loss occured= 0.55434436 and acc= 0.8333333 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=61.0 and loss occured= 0.51165485 and acc= 0.8333333 \n",
      "\n",
      "Step=62.0 and loss occured= 0.41039208 and acc= 0.8666667 \n",
      "\n",
      "Step=63.0 and loss occured= 0.5891734 and acc= 0.78333336 \n",
      "\n",
      "Step=64.0 and loss occured= 0.41135582 and acc= 0.89166665 \n",
      "\n",
      "Step=65.0 and loss occured= 0.510422 and acc= 0.8333333 \n",
      "\n",
      "Step=66.0 and loss occured= 0.6565288 and acc= 0.75 \n",
      "\n",
      "Step=67.0 and loss occured= 0.4523805 and acc= 0.8333333 \n",
      "\n",
      "Step=68.0 and loss occured= 0.5543841 and acc= 0.80833334 \n",
      "\n",
      "Step=69.0 and loss occured= 0.6355794 and acc= 0.75 \n",
      "\n",
      "Step=70.0 and loss occured= 0.57489765 and acc= 0.8 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=71.0 and loss occured= 0.60354906 and acc= 0.7916667 \n",
      "\n",
      "Step=72.0 and loss occured= 0.50903577 and acc= 0.81666666 \n",
      "\n",
      "Step=73.0 and loss occured= 0.4572452 and acc= 0.84166664 \n",
      "\n",
      "Step=74.0 and loss occured= 0.5023061 and acc= 0.825 \n",
      "\n",
      "Step=75.0 and loss occured= 0.47399044 and acc= 0.84166664 \n",
      "\n",
      "Step=76.0 and loss occured= 0.5869588 and acc= 0.7916667 \n",
      "\n",
      "Step=77.0 and loss occured= 0.46389294 and acc= 0.85833335 \n",
      "\n",
      "Step=78.0 and loss occured= 0.49481693 and acc= 0.8333333 \n",
      "\n",
      "Step=79.0 and loss occured= 0.4178953 and acc= 0.84166664 \n",
      "\n",
      "Step=80.0 and loss occured= 0.45319304 and acc= 0.85 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=81.0 and loss occured= 0.5532195 and acc= 0.7916667 \n",
      "\n",
      "Step=82.0 and loss occured= 0.6431265 and acc= 0.75 \n",
      "\n",
      "Step=83.0 and loss occured= 0.66681844 and acc= 0.76666665 \n",
      "\n",
      "Step=84.0 and loss occured= 0.48026562 and acc= 0.825 \n",
      "\n",
      "Step=85.0 and loss occured= 0.61681676 and acc= 0.7583333 \n",
      "\n",
      "Step=86.0 and loss occured= 0.53414285 and acc= 0.81666666 \n",
      "\n",
      "Step=87.0 and loss occured= 0.59983724 and acc= 0.8 \n",
      "\n",
      "Step=88.0 and loss occured= 0.537558 and acc= 0.80833334 \n",
      "\n",
      "Step=89.0 and loss occured= 0.40194932 and acc= 0.875 \n",
      "\n",
      "Step=90.0 and loss occured= 0.5397644 and acc= 0.7916667 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=91.0 and loss occured= 0.57712287 and acc= 0.8 \n",
      "\n",
      "Step=92.0 and loss occured= 0.55373406 and acc= 0.7916667 \n",
      "\n",
      "Step=93.0 and loss occured= 0.5905819 and acc= 0.7583333 \n",
      "\n",
      "Step=94.0 and loss occured= 0.43687248 and acc= 0.8666667 \n",
      "\n",
      "Step=95.0 and loss occured= 0.5489092 and acc= 0.7916667 \n",
      "\n",
      "Step=96.0 and loss occured= 0.43668538 and acc= 0.85833335 \n",
      "\n",
      "Step=97.0 and loss occured= 0.5059591 and acc= 0.825 \n",
      "\n",
      "Step=98.0 and loss occured= 0.4863739 and acc= 0.8666667 \n",
      "\n",
      "Step=99.0 and loss occured= 0.44209412 and acc= 0.85833335 \n",
      "\n",
      "Step=100.0 and loss occured= 0.48913416 and acc= 0.825 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=101.0 and loss occured= 0.62906826 and acc= 0.7416667 \n",
      "\n",
      "Step=102.0 and loss occured= 0.43556446 and acc= 0.84166664 \n",
      "\n",
      "Step=103.0 and loss occured= 0.6209876 and acc= 0.75 \n",
      "\n",
      "Step=104.0 and loss occured= 0.51827085 and acc= 0.84166664 \n",
      "\n",
      "Step=105.0 and loss occured= 0.51879716 and acc= 0.825 \n",
      "\n",
      "Step=106.0 and loss occured= 0.5393663 and acc= 0.7916667 \n",
      "\n",
      "Step=107.0 and loss occured= 0.64042145 and acc= 0.7583333 \n",
      "\n",
      "Step=108.0 and loss occured= 0.6133069 and acc= 0.75 \n",
      "\n",
      "Step=109.0 and loss occured= 0.51520836 and acc= 0.825 \n",
      "\n",
      "Step=110.0 and loss occured= 0.56565183 and acc= 0.78333336 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=111.0 and loss occured= 0.56730574 and acc= 0.8 \n",
      "\n",
      "Step=112.0 and loss occured= 0.5936249 and acc= 0.775 \n",
      "\n",
      "Step=113.0 and loss occured= 0.522142 and acc= 0.8 \n",
      "\n",
      "Step=114.0 and loss occured= 0.40796477 and acc= 0.85833335 \n",
      "\n",
      "Step=115.0 and loss occured= 0.6030923 and acc= 0.76666665 \n",
      "\n",
      "Step=116.0 and loss occured= 0.70867985 and acc= 0.7416667 \n",
      "\n",
      "Step=117.0 and loss occured= 0.43273547 and acc= 0.85 \n",
      "\n",
      "Step=118.0 and loss occured= 0.6028256 and acc= 0.7583333 \n",
      "\n",
      "----Epoch=0.0\n",
      "\n",
      "Step=119.0 and loss occured= 0.36737314 and acc= 0.8833333 \n",
      "\n",
      "Step=120.0 and loss occured= 0.34930688 and acc= 0.84166664 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=121.0 and loss occured= 0.36397016 and acc= 0.85833335 \n",
      "\n",
      "Step=122.0 and loss occured= 0.31089303 and acc= 0.925 \n",
      "\n",
      "Step=123.0 and loss occured= 0.37860918 and acc= 0.85 \n",
      "\n",
      "Step=124.0 and loss occured= 0.33981302 and acc= 0.8666667 \n",
      "\n",
      "Step=125.0 and loss occured= 0.35301286 and acc= 0.875 \n",
      "\n",
      "Step=126.0 and loss occured= 0.3534083 and acc= 0.8666667 \n",
      "\n",
      "Step=127.0 and loss occured= 0.35014996 and acc= 0.875 \n",
      "\n",
      "Step=128.0 and loss occured= 0.4316562 and acc= 0.8333333 \n",
      "\n",
      "Step=129.0 and loss occured= 0.3218311 and acc= 0.875 \n",
      "\n",
      "Step=130.0 and loss occured= 0.36104015 and acc= 0.85 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=131.0 and loss occured= 0.35379112 and acc= 0.8666667 \n",
      "\n",
      "Step=132.0 and loss occured= 0.28100905 and acc= 0.8833333 \n",
      "\n",
      "Step=133.0 and loss occured= 0.31613514 and acc= 0.9 \n",
      "\n",
      "Step=134.0 and loss occured= 0.38520825 and acc= 0.85833335 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step=135.0 and loss occured= 0.38859934 and acc= 0.85833335 \n",
      "\n",
      "Step=136.0 and loss occured= 0.26964563 and acc= 0.9 \n",
      "\n",
      "Step=137.0 and loss occured= 0.33459398 and acc= 0.875 \n",
      "\n",
      "Step=138.0 and loss occured= 0.34496343 and acc= 0.875 \n",
      "\n",
      "Step=139.0 and loss occured= 0.38891333 and acc= 0.85 \n",
      "\n",
      "Step=140.0 and loss occured= 0.3559516 and acc= 0.90833336 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=141.0 and loss occured= 0.27086326 and acc= 0.89166665 \n",
      "\n",
      "Step=142.0 and loss occured= 0.2862477 and acc= 0.90833336 \n",
      "\n",
      "Step=143.0 and loss occured= 0.39075908 and acc= 0.8333333 \n",
      "\n",
      "Step=144.0 and loss occured= 0.36064002 and acc= 0.85 \n",
      "\n",
      "Step=145.0 and loss occured= 0.28961834 and acc= 0.90833336 \n",
      "\n",
      "Step=146.0 and loss occured= 0.31236276 and acc= 0.85833335 \n",
      "\n",
      "Step=147.0 and loss occured= 0.40759692 and acc= 0.8666667 \n",
      "\n",
      "Step=148.0 and loss occured= 0.41216534 and acc= 0.81666666 \n",
      "\n",
      "Step=149.0 and loss occured= 0.3462605 and acc= 0.875 \n",
      "\n",
      "Step=150.0 and loss occured= 0.31011537 and acc= 0.9 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=151.0 and loss occured= 0.25882515 and acc= 0.9 \n",
      "\n",
      "Step=152.0 and loss occured= 0.28932396 and acc= 0.9 \n",
      "\n",
      "Step=153.0 and loss occured= 0.3189346 and acc= 0.8833333 \n",
      "\n",
      "Step=154.0 and loss occured= 0.30603236 and acc= 0.8833333 \n",
      "\n",
      "Step=155.0 and loss occured= 0.24631158 and acc= 0.925 \n",
      "\n",
      "Step=156.0 and loss occured= 0.30586168 and acc= 0.8833333 \n",
      "\n",
      "Step=157.0 and loss occured= 0.38428438 and acc= 0.85 \n",
      "\n",
      "Step=158.0 and loss occured= 0.39683992 and acc= 0.85 \n",
      "\n",
      "Step=159.0 and loss occured= 0.35593948 and acc= 0.9166667 \n",
      "\n",
      "Step=160.0 and loss occured= 0.32890704 and acc= 0.8666667 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=161.0 and loss occured= 0.35348746 and acc= 0.8666667 \n",
      "\n",
      "Step=162.0 and loss occured= 0.46344912 and acc= 0.8 \n",
      "\n",
      "Step=163.0 and loss occured= 0.31553558 and acc= 0.85833335 \n",
      "\n",
      "Step=164.0 and loss occured= 0.2925684 and acc= 0.89166665 \n",
      "\n",
      "Step=165.0 and loss occured= 0.34552866 and acc= 0.9166667 \n",
      "\n",
      "Step=166.0 and loss occured= 0.30133203 and acc= 0.8833333 \n",
      "\n",
      "Step=167.0 and loss occured= 0.31241623 and acc= 0.8833333 \n",
      "\n",
      "Step=168.0 and loss occured= 0.3589597 and acc= 0.8833333 \n",
      "\n",
      "Step=169.0 and loss occured= 0.40109938 and acc= 0.85 \n",
      "\n",
      "Step=170.0 and loss occured= 0.32325 and acc= 0.8666667 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=171.0 and loss occured= 0.3800527 and acc= 0.875 \n",
      "\n",
      "Step=172.0 and loss occured= 0.4116358 and acc= 0.84166664 \n",
      "\n",
      "Step=173.0 and loss occured= 0.2658055 and acc= 0.90833336 \n",
      "\n",
      "Step=174.0 and loss occured= 0.39507243 and acc= 0.825 \n",
      "\n",
      "Step=175.0 and loss occured= 0.35296503 and acc= 0.85 \n",
      "\n",
      "Step=176.0 and loss occured= 0.32557198 and acc= 0.8833333 \n",
      "\n",
      "Step=177.0 and loss occured= 0.3555134 and acc= 0.85 \n",
      "\n",
      "Step=178.0 and loss occured= 0.32984045 and acc= 0.85833335 \n",
      "\n",
      "----Epoch=0.0\n",
      "\n",
      "Step=179.0 and loss occured= 0.13580862 and acc= 0.98333335 \n",
      "\n",
      "Step=180.0 and loss occured= 0.15586492 and acc= 0.98333335 \n",
      "\n",
      "saving model\n",
      "\n",
      "Step=181.0 and loss occured= 0.16162588 and acc= 0.96666664 \n",
      "\n",
      "Step=182.0 and loss occured= 0.1572728 and acc= 0.9583333 \n",
      "\n",
      "Step=183.0 and loss occured= 0.14156295 and acc= 0.96666664 \n",
      "\n",
      "Step=184.0 and loss occured= 0.12094709 and acc= 0.975 \n",
      "\n",
      "Step=185.0 and loss occured= 0.12946568 and acc= 0.975 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-ceeb3793bf5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#     model.save_model(sess,\"1st_try\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_validation_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_every_n_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_train_every_n_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlog_validation_every_n_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mset_logging\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;31m#     for x,y in data.get_next_batch():\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#         print (x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-048fd297deb3>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sess, n_epochs, get_next_batch_fn, get_validation_set_fn, save_every_n_iter, log_train_every_n_iter, log_validation_every_n_iter, save_dir, initialize, set_logging)\u001b[0m\n\u001b[0;32m    158\u001b[0m                     \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m                     \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_step_no\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_no\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m                 \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"Step={} and loss occured= {} and acc= {} \\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;31m#freeing memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs=50\n",
    "n_iter=int(data.X_train.shape[0]/data.batch_size)\n",
    "save_every_n_iter=10\n",
    "log_train_every_n_iter=5\n",
    "log_validation_every_n_iter=10\n",
    "initialize=False\n",
    "save_dir=\"3rd_try\"\n",
    "tf.reset_default_graph()\n",
    "# model=CNN_Model(params)\n",
    "\n",
    "    \n",
    "\n",
    "model=\"\"\n",
    "with tf.Session() as sess:\n",
    "    if(not initialize):\n",
    "        model=CNN_Model(restore_params=True,pickle_file_path=\"1st_try/neural_network_v1/model_object.pkl\")\n",
    "        model.build_model()\n",
    "        model.restore_model(sess,save_dir)\n",
    "        model.params.learning_rate=0.001\n",
    "    else:\n",
    "        model=CNN_Model(params)\n",
    "        model.build_model()\n",
    "#         model.params.step_no=765\n",
    "#     sess.run(model.initializer)\n",
    "#     model.save_model(sess,\"1st_try\")\n",
    "\n",
    "    model.train(sess,n_epochs,data.get_next_batch,data.get_validation_set,save_every_n_iter,log_train_every_n_iter,log_validation_every_n_iter,save_dir=save_dir,initialize=initialize,set_logging=True)\n",
    "#     for x,y in data.get_next_batch():\n",
    "#         print (x.shape)\n",
    "#         print (y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
