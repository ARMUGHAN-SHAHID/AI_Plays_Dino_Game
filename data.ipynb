{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    \n",
    "    def __init__(self,data_path,batch_size=120,load_directly=False,X_data_path=\"\",Y_data_path=\"\",train_proportion=None):\n",
    "        if batch_size>10:\n",
    "            self.batch_size=batch_size\n",
    "        else:\n",
    "            self.batch_size=50\n",
    "        if not load_directly:\n",
    "            if os.path.exists(data_path):\n",
    "                self.process_data_and_write_to_disk(data_path)\n",
    "\n",
    "            elif os.path.exists(os.path.join(os.getcwd(),data_path)):\n",
    "                self.process_data_and_write_to_disk(os.path.join(os.getcwd(),data_path))\n",
    "            else:\n",
    "                print (\"no such file exists...Returning without loading any Data\")\n",
    "        else:\n",
    "            self.load_data(X_data_path,Y_data_path,train_proportion)\n",
    "    \n",
    "    def process_data_and_write_to_disk(self,data_path,train_proportion=None,file_prefix=\"data\"):\n",
    "        \n",
    "        self.data_path=data_path\n",
    "        data=np.load(self.data_path)\n",
    "        self.data_size=len(data)\n",
    "        print (\"Data size= \"+str(self.data_size))\n",
    "        X,Y=np.expand_dims(data[0][0],axis=0),np.expand_dims(np.array(data[0][1]),axis=0) #expanding dims \n",
    "        for i in np.arange(1,self.data_size):\n",
    "#             print (i)\n",
    "            X=np.concatenate((X,np.array([data[i][0]])),axis=0)\n",
    "            Y=np.concatenate((Y,np.array([data[i][1]])),axis=0)\n",
    "            \n",
    "        X=np.expand_dims(X,axis=3)#because current data only 2d\n",
    "        np.save(file_prefix+\"_X.npy\",X)\n",
    "        np.save(file_prefix+\"_Y.npy\",Y)\n",
    "        X,Y=None,None\n",
    "        self.load_data(file_prefix+\"_X.npy\",file_prefix+\"_Y.npy\",train_proportion)\n",
    "        \n",
    "    def load_data(self,X_data_path,Y_data_path,train_proportion):\n",
    "        if os.path.exists(X_data_path) and os.path.exists(Y_data_path):\n",
    "            X=np.load(X_data_path)\n",
    "            Y=np.load(Y_data_path)\n",
    "            self.X_train,self.X_test,self.Y_train,self.Y_test=train_test_split(X,Y,train_size=train_proportion)\n",
    "            X,Y=None,None\n",
    "        else:\n",
    "            print (\"failed to load data\")\n",
    "    def get_next_batch(self):\n",
    "        train_size=self.X_train.shape[0]\n",
    "        num_batches=int(train_size/self.batch_size)\n",
    "        inds=np.arange(train_size)\n",
    "        np.random.shuffle(inds)\n",
    "        X_train,Y_train=self.X_train[inds],self.Y_train[inds]\n",
    "        for i in np.arange(num_batches):\n",
    "            yield X_train[(i*self.batch_size):(i*self.batch_size)+self.batch_size],Y_train[(i*self.batch_size):(i*self.batch_size)+self.batch_size]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
