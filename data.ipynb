{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/armughan/anaconda3/envs/py3.6/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    \n",
    "    def __init__(self,data_path,batch_size=120,load_directly=False,X_data_path=\"\",Y_data_path=\"\",train_proportion=None):\n",
    "        if batch_size>10:\n",
    "            self.batch_size=batch_size\n",
    "        else:\n",
    "            self.batch_size=50\n",
    "        if not load_directly:\n",
    "            if os.path.exists(data_path):\n",
    "                self.process_data_and_write_to_disk(data_path)\n",
    "\n",
    "            elif os.path.exists(os.path.join(os.getcwd(),data_path)):\n",
    "                self.process_data_and_write_to_disk(os.path.join(os.getcwd(),data_path))\n",
    "            else:\n",
    "                print (\"no such file exists...Returning without loading any Data\")\n",
    "        else:\n",
    "            self.load_data(X_data_path,Y_data_path,train_proportion)\n",
    "    \n",
    "    def process_data_and_write_to_disk(self,data_path,train_proportion=None,file_prefix=\"data\"):\n",
    "        \n",
    "        self.data_path=data_path\n",
    "        data=np.load(self.data_path)\n",
    "        self.data_size=len(data)\n",
    "        print (\"Data size= \"+str(self.data_size))\n",
    "        X,Y=np.expand_dims(data[0][0],axis=0),np.expand_dims(np.array(data[0][1]),axis=0) #expanding dims \n",
    "        for i in np.arange(1,self.data_size):\n",
    "#             print (i)\n",
    "            X=np.concatenate((X,np.array([data[i][0]])),axis=0)\n",
    "            Y=np.concatenate((Y,np.array([data[i][1]])),axis=0)\n",
    "            \n",
    "        X=np.expand_dims(X,axis=3)#because current data only 2d\n",
    "        np.save(file_prefix+\"_X.npy\",X)\n",
    "        np.save(file_prefix+\"_Y.npy\",Y)\n",
    "        X,Y=None,None\n",
    "        self.load_data(file_prefix+\"_X.npy\",file_prefix+\"_Y.npy\",train_proportion)\n",
    "        \n",
    "    def load_data(self,X_data_path,Y_data_path,train_proportion):\n",
    "        if os.path.exists(X_data_path) and os.path.exists(Y_data_path):\n",
    "            X=np.load(X_data_path)\n",
    "            Y=np.load(Y_data_path)\n",
    "            np.random.shuffle(X)\n",
    "            np.random.shuffle(Y)\n",
    "            X_temp,self.X_test,Y_temp,self.Y_test=train_test_split(X,Y,train_size=train_proportion)\n",
    "            self.X_train,self.X_validation,self.Y_train,self.Y_validation=train_test_split(X_temp,Y_temp,train_size=train_proportion)\n",
    "            train_size=self.X_train.shape[0]\n",
    "            self.num_batches=int(train_size/self.batch_size)\n",
    "            X_temp=Y_temp=None\n",
    "            X,Y=None,None\n",
    "        else:\n",
    "            print (\"failed to load data\")\n",
    "    def get_next_batch(self):\n",
    "        inds=np.arange(self.X_train.shape[0])#shuffling training set for every new epoch\n",
    "        np.random.shuffle(inds)\n",
    "        X_train,Y_train=self.X_train[inds],self.Y_train[inds]\n",
    "        for i in np.arange(self.num_batches):\n",
    "            yield X_train[(i*self.batch_size):(i*self.batch_size)+self.batch_size],Y_train[(i*self.batch_size):(i*self.batch_size)+self.batch_size]\n",
    "    def get_validation_set(self):\n",
    "        return self.X_validation,self.Y_validation\n",
    "    def get_shapes(self):\n",
    "        return {\n",
    "            'X_train shape': self.X_train.shape,\n",
    "            'Y_train shape': self.Y_train.shape,\n",
    "            'X_validation shape': self.X_validation.shape,\n",
    "            'Y_validation shape': self.Y_validation.shape,\n",
    "            'X_test shape': self.X_test.shape,\n",
    "            'Y_test shape': self.Y_test.shape\n",
    "        }\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
